---
title: Transformer_Intro
issueNo: 
tags: 
date: 2024-03-21T17:21:00
Draft: false
---
# 00.

# 1. 原理
# 1 .1 注意力机制和自注意力机制

### 1.1.1 注意力机制（attention）

>人在处理信息的时候，会将注意力放在需要关注的信息上，对于其他无关的外部信息进行过滤，这种处理方式被称为注意力机制。

* 自主提示：经过「先验知识」的介入下，对具有「先验权重」的物体引起的注意力倾向
* 非自主提示：因物体「本身特征」突出引起的注意力倾向

以「软寻址」理解自主提示：

通过计算 Key 和 Query 的「**相似度**」来进行寻址，这种方法不只是获取一个 Key 地址中存储器的 Value 值，而是获取所有的存储器中的 Value 值的加权和。

至于每个 Value 的权重（重要程度），是通过 Key 和 Query 相似度计算得到的，最终的输出是所有 Value 值和其权重的加权和。


键（Key）和值（Value）理解为一种软寻址（）
Value 可以看作存储器存储的内容，Key 看作是存储器的地址。当 KeyQuery 时，则取出 Key 地址对应存储器中的 Value 值，这被称为硬寻址。而软寻址则是如下图所示：

![|400](https://picgoyue.oss-cn-hangzhou.aliyuncs.com/20240321214859.png)